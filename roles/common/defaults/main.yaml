---
# =============================================================================
# Disk Configuration
# =============================================================================
#
# Select a predefined disk profile or set to "none" to skip disk setup entirely.
# Available profiles:
#   - aws_raid_1: Auto-discover instance store disks, RAID-1 (mirrored)
#   - aws_raid_0: Auto-discover instance store disks, RAID-0 (striped)
#   - aws_ebs_backup_node: NVMe for rollup/logs + EBS for snapshots
#   - aws_ebs_backup_node_raid0: RAID-0 for rollup + EBS for snapshots
#   - aws_simple: Single disk for rollup, separate logs disk
#   - raid_manual: RAID-1 for rollup (2 disks), explicit paths
#   - hetzner: Single disk for rollup, logs on root volume
#   - none: Skip disk setup (use existing mounts or root volume)
#
disk_profile: "none"

# Predefined disk profiles
#
# Auto-discover profiles use disk_model to find disks by matching lsblk MODEL column.
# Common disk_model patterns:
#   - "Amazon EC2 NVMe Instance Storage"  - AWS instance store
#   - "INTEL SSDPE"                       - Intel NVMe SSDs
#   - "NVMe"                              - Generic NVMe (broad match)
#   - "SAMSUNG"                           - Samsung SSDs
#
disk_profiles:
  # AWS: Auto-discover instance store disks for RAID-1 (mirrored)
  # 1st + 2nd disk → RAID-1, 3rd disk → logs
  aws_raid_1:
    auto_discover: true
    disk_model: "Amazon EC2 NVMe Instance Storage"
    use_raid: true
    raid_level: 1
    raid_disk_count: 2
    logs_disk_index: 2
    da_disk_index: null

  # AWS: Auto-discover instance store disks for RAID-0 (striped)
  # 1st + 2nd disk → RAID-0, 3rd disk → logs
  aws_raid_0:
    auto_discover: true
    disk_model: "Amazon EC2 NVMe Instance Storage"
    use_raid: true
    raid_level: 0
    raid_disk_count: 2
    logs_disk_index: 2
    da_disk_index: null

  # AWS: Backup node with NVMe for rollup/logs + EBS for snapshots
  # 1st NVMe → rollup, 2nd NVMe → logs, EBS → /mnt/snapshots
  aws_ebs_backup_node:
    auto_discover: true
    disk_model: "Amazon EC2 NVMe Instance Storage"
    ebs_serial_prefix: "vol"
    use_raid: false
    rollup_disk_index: 0
    logs_disk_index: 1
    da_disk_index: null
    snapshots_disk_from_ebs: true

  # AWS: Backup node with RAID-0 for rollup + EBS for snapshots
  # 1st + 2nd NVMe → RAID-0, 3rd NVMe → logs, EBS → /mnt/snapshots
  aws_ebs_backup_node_raid0:
    auto_discover: true
    disk_model: "Amazon EC2 NVMe Instance Storage"
    ebs_serial_prefix: "vol"
    use_raid: true
    raid_level: 0
    raid_disk_count: 2
    logs_disk_index: 2
    da_disk_index: null
    snapshots_disk_from_ebs: true

  # AWS: Auto-discover instance store disks, no RAID
  # 1st disk → rollup, 2nd disk → logs
  aws_simple:
    auto_discover: true
    disk_model: "Amazon EC2 NVMe Instance Storage"
    use_raid: false
    rollup_disk_index: 0
    logs_disk_index: 1
    da_disk_index: null

  raid_manual:
    use_raid: true
    raid_level: 1
    raid_disks:
      - "/dev/nvme1n1"
      - "/dev/nvme2n1"
    logs_disk: ""
    da_disk: ""

  hetzner:
    use_raid: false
    rollup_disk: "/dev/nvme1n1"
    logs_disk: ""
    da_disk: ""

  none:
    use_raid: false
    rollup_disk: ""
    logs_disk: ""
    da_disk: ""

# Custom disk configuration (used when disk_profile: "custom")
# disk_custom:
#   use_raid: true
#   raid_disks: ["/dev/sda", "/dev/sdb"]
#   logs_disk: "/dev/sdc"
#   da_disk: "/dev/sdd"

# Reformat existing disks. Use with caution - this will DESTROY all data!
# When true: unmounts existing mounts, destroys RAID arrays, reformats disks
reformat_disks: false

# Mount points (typically no need to change these)
rollup_storage_dir: "/mnt/rollup"
rollup_log_dir: "/mnt/logs"  # Only used when logs_disk is configured; otherwise journald uses default location
da_store: "/mnt/da"
snapshots_dir: "/mnt/snapshots"  # Used by aws_ebs_backup_node profile for EBS-backed snapshots

# File limits for users
# These are high values suitable for services that need to handle many connections
max_open_files: 1000000

# Uncomment this if the custom host label is needed for monitoring.
# Will be used in telegraf and grafana services
# custom_host_label: "soak-benchmark-aws-2025-q1"

# Telegraf configuration
influxdb_remote_url: "http://influxdb.sov-obs.xyz:8086"
influxdb_org: "Sovereign Labs"
influxdb_bucket: "sov-dev"

# Loki configuration
grafana_loki_url: "https://loki.sov-obs.xyz/loki/api/v1/push"
grafana_loki_username: "sov-logger"

# Tempo configuration
grafana_tempo_endpoint: "tempo.sov-obs.xyz:443"
grafana_tempo_username: "sov-logger"

# OpenTelemetry availability flag
# Automatically set based on whether grafana_loki_token or grafana_tempo_token are configured
# This is used by the rollup role to determine if telemetry should be enabled
opentelemetry_available: "{{ (grafana_loki_token | default('') | length > 0) or (grafana_tempo_token | default('') | length > 0) }}"

